Becoming a data engineer involves a combination of technical skills, hands-on experience, and a mindset geared towards solving data-related challenges. Here's a lean study routine to help you become a data engineer:

1. Learn the Basics of Data Engineering:

Platforms: Start with cloud platforms like AWS, Google Cloud, or Microsoft Azure, as they are widely used in the industry.
Tools: Get familiar with fundamental data engineering tools like Apache Hadoop, Apache Spark, and Apache Kafka.
Books: Consider reading "Data Engineering" by Maxime Beauchemin and "Streaming Systems" by Tyler Akidau, Slava Chernyak, and Erik Meijer.
Mindset: Develop a problem-solving mindset. Understand that data engineering involves solving complex data integration and processing challenges.
2. Master SQL and Databases:

Platforms: Learn SQL on platforms like SQLZoo, LeetCode, or Hackerrank.
Tools: Gain proficiency in database management systems (DBMS) such as PostgreSQL, MySQL, or NoSQL databases like MongoDB.
Books: Study "SQL Performance Explained" by Markus Winand to understand how to optimize SQL queries.
3. Understand Data Modeling:

Tools: Learn how to design data models using tools like ER diagrams and use cases. Consider using platforms like dbdiagram.io.
Books: "Designing Data-Intensive Applications" by Martin Kleppmann is a great resource for understanding data modeling concepts.
4. Explore ETL (Extract, Transform, Load):

Tools: Get hands-on experience with ETL tools like Apache NiFi, Talend, or Apache Airflow.
Tutorials: Follow online tutorials and examples to understand data extraction, transformation, and loading processes.
5. Cloud Services and Big Data Technologies:

Platforms: Dive into cloud-based data engineering services offered by AWS (e.g., AWS Glue), Google Cloud (e.g., Dataflow), and Azure (e.g., Azure Data Factory).
Tools: Learn big data technologies such as Apache Hadoop, Apache Spark, Apache Kafka, and Hadoop ecosystem tools (Hive, HBase, etc.).
6. Version Control and Collaboration:

Tools: Learn version control systems like Git and understand how to collaborate on coding projects using platforms like GitHub or GitLab.
7. Automation and Scripting:

Programming Languages: Choose a programming language to automate data engineering tasks. Python is a popular choice due to its extensive libraries.
Tools: Explore scripting tools like Bash for automation and data pipeline orchestration.
8. Continuous Learning:

Online Courses: Consider taking online courses on platforms like Coursera, edX, or Udemy. Courses like "Data Engineering on Google Cloud" or "AWS Certified Data Analytics" can be beneficial.
Blogs and Forums: Follow data engineering blogs, forums like Stack Overflow, and communities like Reddit's r/dataengineering to stay updated.
9. Real-World Projects:

Personal Projects: Apply your knowledge by working on personal data engineering projects. Start small and gradually increase complexity.
Contributions: Contribute to open-source data engineering projects on GitHub to gain practical experience.
10. Networking and Collaboration:

Meetups and Conferences: Attend data engineering meetups, conferences, and webinars to network with professionals and learn about industry trends.
Remember that becoming a proficient data engineer takes time and practical experience. Be patient, practice regularly, and continually seek to expand your skills. Keep up with industry developments, as the field of data engineering is constantly evolving.